任务：

1. 将分端口和分方向的模型准确率恢复到历史最好成绩（历史最好成绩的做法只记得个大概，细节不明确）
    历史最好成绩包含下面三个特点：
    1） 删除10月1日到10月7日所有数据
    2） 分端口，方向建模
    3） 时间因素选择的是连续型变量
    4） 使用的是调参gbdt模型

2. 在原来的基础上加stacking模型和纯时间特征模型（效果比之前的好）
    1) 在使用纯时间特征时，不分端口和方向的效果要优于分端口和方向的情况


2017-05-11

1. 在单模型的基础上加上一个清洗脏数据的功能，用三层gbdt清洗掉百分之十的数据，再用五层GBDT预测（不知道为什么才0.7876）

2. 纯时间特征模型加上数值类型的时间特征（成功从0.2016提高到了0.1730）

3. stacking1使用的训练集做微小调整，在构造训练集过程中不处理nan值，拿到模型里才处理，这样训练集的Volume0～volume5和y之间更有连贯性（0.1788已经被纯时间特征超过了）


2017-05-12

1. 重新提交2017-05-11日第一个优化点（>0.3）

2. 在2017-5-11的基础上减少stacking2模型的数量，纯时间模型去掉ADAboost(0.1775)

3. 检查训练集，在2017-05-11的基础上减少stacking1模型的数据，去掉所有ADAboost模型，二层不适用随机模型，尽量减少模型之间的相关度（0.1735）

2017-05-13

1. 在2017-05-12基础上修改过滤时的评分函数

2. 修正时间特征计算代码0.1681

3. stacking的第二层备选模型中去掉随机模型（ET和RF）(0.1739)

2017-05-15

1. 在2017-05-13项目1的基础上，舍弃数据过滤功能，改成特征选取功能，功能按照单个特征做回归的评分高低降序排序，每次选取一个效果最好的特征加到备选集中，并预测打分，得到最好的特征集（0.1841降了）

2017-05-18 都是单模型调整

1. GBDT3层和5层有没有区别，可以尝试一下，而且注意用评价函数（3层效果好，说明5层有严重的过拟合）

2. 加一些特征吧，比如说最大值，最小值（0.1747）

2017-05-17 训练集和预测集数据分析

发现不论是原始的训练集还是原始的预测集，0方向（entry）的车辆都不记录vehicle_type，而1方向（exit）的方向都记录了该值
所以不能盲目用众数来填充vehicle_type的空值，在分端口和方向的时候适当剔除掉一些特征

3层GBDT（0.1627）

存在7万条记录没有载重量，而且全部都是各端口0方向，都没用电子桩（暂时不做处理，因为题目也说载重量是0到7，说明0载重量是存在的）

2017-05-18

1. 在昨天基础上，删除处理后产生的空值，之前我都是在stacking文件里专门处理训练集和预测集的空值，在volume_predict2文件里
   没有这功能。（0.1683）

2. 在昨天基础上，增加层数到5层（0.1694）

过拟合了，想想怎么肥四

2017-05-19

1. 把10月1日到10月7日的数据加回来，增加部分特征，包括20分钟内使用etc的车辆数、总载重量，没使用etc的车辆数、总载重量

2017-05-21

两种筛选训练集方式

1. 按照预测集分布筛选，用预测集车流的最大值，最小值，均值，标准差压缩训练集vloume0 ~ volume5的区间，注意用均值加减二倍标准差和
   最大值，最小值比较（0.1687）

2. 直接用训练集本身的分布特点筛选数据，用训练集的最大值，最小值，均值，标准差压缩区间，均值加二倍标准差为上限，
   下限设置常数3（0.1692）

之前单模型提交的数据结果及方式概要：

0.1672 分端口方向构造不同的特征，10月1日到10月7日数据全部变成null，但是当时忘记删除这些值，将其全部填成0

0.1747 在上面的基础上删除所有的空值

0.1647 在上面的基础上删除部分特征，包括最大值，最小值，均值等特征

0.1658 考虑到大量的0数据能够改变树的分布，将部分较小的数值隔离开，因此想增加10月1日至10月7日数据来平衡数据分布

0.1687 用测试集的最大值，最小值，均值，方差清洗数据，均值加减二倍方差

0.1692 用训练集的最大值，最小值，均值，方差清洗数据，均值加减二倍方差和最大值，最小值，用最大区间


2017-05-22

暂时放弃上述两种数据清洗方式，使用如下数据清理方式：

1. 10月1日至10月7日数据全部删除

2. 除此之外，其余数据resample得到的空值均填为0

待提交方法

1. 用之前的非调参stacking模型+时间特征模型的融合（0.1728， 0.1617）

2. 使用另一种stacking方式，二层固定使用两种参数的XGB和一个GBDT，一层使用三种模型集合，集合长度分别为6,7,6（0.1673，0.1602）

3. 单模型调整，单独剔除10月1日到10月7日的数据（保证resample之后没有这个东西），在此基础上将所有的空值设置为0（0.1674）

2017-05-23

1. 单模型调整，删除全部空值（尽量合理删除空值），顺便检查代码

2. 把1放到05-22的第二个stacking模型中

3. 时间特征模型调参，可以稍微过拟合，目的是降低和主train&test1模型的相关度，0.5x+0.5y的比例分配结果，最后成绩是0.1589

description of the feature:

Traffic Volume through the Tollgates

time           datatime        the time when a vehicle passes the tollgate

tollgate_id    string          ID of the tollgate

direction      string           0:entry, 1:exit

vehicle_model  int             this number ranges from 0 to 7, which indicates the capacity of the vehicle(bigger the higher)

has_etc        string          does the vehicle use ETC (Electronic Toll Collection) device? 0: No, 1: Yes

vehicle_type   string          vehicle type: 0-passenger vehicle, 1-cargo vehicle

volume_predict.py建模思路：

创建训练集，总的要求就是以前两个小时数据为训练集，用迭代式预测方法
例如8点-10点的数据预测10点20,8点-10点20预测10点40……，每一次预测使用的都是独立的（可能模型一样）的模型
现在开始构建训练集

第一个训练集特征是所有两个小时（以20分钟为一个单位）的数据，因变量是该两小时之后20分钟的流量

第二个训练集，特征是所有两个小时又20分钟（以20分钟为一个单位）的数据，因变量是该两个小时之后20分钟的流量
以此类推训练12个GBDT模型，其中entry 6个，exit 6个

待优化思路：
1. 该模型想说明的问题是当前待预测时段的车流只和之前两小时车流有线性（或非线性）关系，这个认识其实比较局限，因此可以从
   两个方面优化：第一个是增加特征，凭经验构建特征；第二个是换一个角度思考，当前时刻的车流量也可能和之前一个月同一时段
   车流量呈线性（或非线性）关系

2. 如何证明分开考虑收费站比将收费站全部整合到一起效果好，如果将收费站整合到一起的话，那么就不对收费站id，出入方向做分类

优化思路：
1. 根据题目所给评价函数，如果将y转换成log(y)，那么损失函数可以朝lad方向梯度下降（过程已经大致证明了），而特征的log处理
   不影响CART的回归结果，所以对所有车流量（不论特征还是因变量都做log计算）。如果使用其他非树形结构模型需要考虑是否要对
   所有数据做log计算
   
volume_predict2.py
在volume_predict的基础上改进模型

建模思路：

创建训练集，总的要求就是以前两个小时数据为训练集，用迭代式预测方法

例如8点-10点的数据预测10点20,8点-10点20预测10点40……，每一次预测使用的都是独立的（可能模型一样）的模型
现在开始构建训练集

第一个训练集特征是所有两个小时（以20分钟为一个单位）的数据，因变量是该两小时之后20分钟的流量

第二个训练集，特征是所有两个小时又20分钟（以20分钟为一个单位）的数据，因变量是该两个小时之后20分钟的流量
以此类推训练12个GBDT模型，其中entry 6个，exit 6个

待优化思路：
1. 该模型想说明的问题是当前待预测时段的车流只和之前两小时车流有线性（或非线性）关系，这个认识其实比较局限，可以尝试
   换一个角度思考，当前时刻的车流量也可能和之前一个月同一时段车流量呈线性（或非线性）关系

2. 如何证明分开考虑收费站比将收费站全部整合到一起效果好，如果将收费站整合到一起的话，那么就不对收费站id，出入方向做分类

优化思路：
1. 根据题目所给评价函数，如果将y转换成log(y)，那么损失函数可以朝lad方向梯度下降（过程已经大致证明了），而特征的log处理
   不影响CART的回归结果，所以对所有车流量（不论特征还是因变量都做log计算）。如果使用其他非树形结构模型需要考虑是否要对
   所有数据做log计算

2. 增加特征，之前只考虑20分钟内的车流量情况，现在加上在20分钟内的总载重量，平均载重量；货车数量，货车总载重量，货车平均
   载重量；客车数量，客车总载重量，客车平均载重量；使用电子桩的车数（2个小时6个时段，每个时段有10维特征，一共60维）；
   2小时内总载重量，平均载重量，货车数量，货车总载重量，货车平均载重量，客车数量，客车总载重量，客车平均载重量（10维）；
   总计70维特征
